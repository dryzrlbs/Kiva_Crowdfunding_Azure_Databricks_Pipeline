{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72ecad9f-9cf9-4b7b-a331-c5ba324fb72a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook: Incremental CSV to Bronze Transformation\n",
    "# This notebook reads CSV file from ADLS Gen2 and writes incrementally to Bronze layer\n",
    "\n",
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1438f4c-cf27-454c-adf3-f5fc3ef62871",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "dbutils.widgets.text(\"csv_path\", \"abfss://code@kivastorageacc2.dfs.core.windows.net/kiva_loans2.csv\", \"CSV File Path (ADLS)\")\n",
    "dbutils.widgets.text(\"bronze_container\", \"kivabronze\", \"Bronze Container Name\")\n",
    "dbutils.widgets.text(\"storage_account_name\", \"kivastorageacc2\", \"Storage Account Name\")\n",
    "dbutils.widgets.text(\"incremental_key\", \"id\", \"Incremental Loading Key Column\")\n",
    "dbutils.widgets.dropdown(\"overwrite_partition\", \"false\", [\"true\", \"false\"], \"Overwrite Existing Partition\")\n",
    "\n",
    "storage_account_key = \"YOUR_STORAGE_ACCOUNT_KEY\"  # Replace with your storage account key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f83437ba-e2e2-43b5-b273-f6a44d8fd57e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_path=\"abfss://code@kivastorageacc2.dfs.core.windows.net/kiva_loans2.csv\"\n",
    "bronze_container= \"kivabronze\"\n",
    "storage_account_name= \"kivastorageacc2\"\n",
    "incremental_key=\"id\"\n",
    "overwrite_partition= \"false\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a19e012e-01ea-45cc-931b-38c8d75994fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage account kivastorageacc2 authentication configured\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\", storage_account_key)\n",
    "print(f\"Storage account {storage_account_name} authentication configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ee3ae96-002b-48fa-a601-91f5833c4028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get widget values from Databricks\n",
    "csv_path = dbutils.widgets.get(\"csv_path\")\n",
    "bronze_container = dbutils.widgets.get(\"bronze_container\")\n",
    "storage_account_name = dbutils.widgets.get(\"storage_account_name\")\n",
    "\n",
    "incremental_key = dbutils.widgets.get(\"incremental_key\")\n",
    "overwrite_partition = dbutils.widgets.get(\"overwrite_partition\").lower() == \"true\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561e3764-6abc-49c7-a89e-a713d432f5ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file to be read: abfss://code@kivastorageacc2.dfs.core.windows.net/kiva_loans.csv\n",
      "Bronze base path: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net\n"
     ]
    }
   ],
   "source": [
    "# Display CSV full path\n",
    "print(f\"CSV file to be read: {csv_path}\")\n",
    "\n",
    "# Create bronze layer path for ADLS Gen2\n",
    "bronze_base_path = f\"abfss://{bronze_container}@{storage_account_name}.dfs.core.windows.net\"\n",
    "print(f\"Bronze base path: {bronze_base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5b24afb-2c2f-40ae-b18e-f7cbb95cebdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file: abfss://code@kivastorageacc2.dfs.core.windows.net/kiva_loans.csv\n",
      "CSV file read. New data row count: 672113\n",
      "Schema information:\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- funded_amount: string (nullable = true)\n",
      " |-- loan_amount: string (nullable = true)\n",
      " |-- activity: string (nullable = true)\n",
      " |-- sector: string (nullable = true)\n",
      " |-- use: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- partner_id: string (nullable = true)\n",
      " |-- posted_time: timestamp (nullable = true)\n",
      " |-- disbursed_time: string (nullable = true)\n",
      " |-- funded_time: string (nullable = true)\n",
      " |-- term_in_months: string (nullable = true)\n",
      " |-- lender_count: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- borrower_genders: string (nullable = true)\n",
      " |-- repayment_interval: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- posted_year: integer (nullable = true)\n",
      " |-- posted_month: integer (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = false)\n",
      " |-- batch_id: string (nullable = false)\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>funded_amount</th><th>loan_amount</th><th>activity</th><th>sector</th><th>use</th><th>country_code</th><th>country</th><th>region</th><th>currency</th><th>partner_id</th><th>posted_time</th><th>disbursed_time</th><th>funded_time</th><th>term_in_months</th><th>lender_count</th><th>tags</th><th>borrower_genders</th><th>repayment_interval</th><th>date</th><th>posted_year</th><th>posted_month</th><th>ingestion_date</th><th>batch_id</th></tr></thead><tbody><tr><td>653051</td><td>300.0</td><td>300.0</td><td>Fruits & Vegetables</td><td>Food</td><td>To buy seasonal, fresh fruits to sell. </td><td>PK</td><td>Pakistan</td><td>Lahore</td><td>PKR</td><td>247.0</td><td>2014-01-01T06:12:39Z</td><td>2013-12-17 08:00:00+00:00</td><td>2014-01-02 10:06:32+00:00</td><td>12.0</td><td>12</td><td>null</td><td>female</td><td>irregular</td><td>2014-01-01</td><td>2014</td><td>1</td><td>2025-05-22T08:10:04.626Z</td><td>adb0de9d-7c7e-4448-94f6-e01cd2c07765</td></tr><tr><td>653053</td><td>575.0</td><td>575.0</td><td>Rickshaw</td><td>Transportation</td><td>to repair and maintain the auto rickshaw used in their business.</td><td>PK</td><td>Pakistan</td><td>Lahore</td><td>PKR</td><td>247.0</td><td>2014-01-01T06:51:08Z</td><td>2013-12-17 08:00:00+00:00</td><td>2014-01-02 09:17:23+00:00</td><td>11.0</td><td>14</td><td>null</td><td>female, female</td><td>irregular</td><td>2014-01-01</td><td>2014</td><td>1</td><td>2025-05-22T08:10:04.626Z</td><td>adb0de9d-7c7e-4448-94f6-e01cd2c07765</td></tr><tr><td>653068</td><td>150.0</td><td>150.0</td><td>Transportation</td><td>Transportation</td><td>To repair their old cycle-van and buy another one to rent out as a source of income</td><td>IN</td><td>India</td><td>Maynaguri</td><td>INR</td><td>334.0</td><td>2014-01-01T09:58:07Z</td><td>2013-12-17 08:00:00+00:00</td><td>2014-01-01 16:01:36+00:00</td><td>43.0</td><td>6</td><td>user_favorite, user_favorite</td><td>female</td><td>bullet</td><td>2014-01-01</td><td>2014</td><td>1</td><td>2025-05-22T08:10:04.626Z</td><td>adb0de9d-7c7e-4448-94f6-e01cd2c07765</td></tr><tr><td>653063</td><td>200.0</td><td>200.0</td><td>Embroidery</td><td>Arts</td><td>to purchase an embroidery machine and a variety of new embroidery materials.</td><td>PK</td><td>Pakistan</td><td>Lahore</td><td>PKR</td><td>247.0</td><td>2014-01-01T08:03:11Z</td><td>2013-12-24 08:00:00+00:00</td><td>2014-01-01 13:00:00+00:00</td><td>11.0</td><td>8</td><td>null</td><td>female</td><td>irregular</td><td>2014-01-01</td><td>2014</td><td>1</td><td>2025-05-22T08:10:04.626Z</td><td>adb0de9d-7c7e-4448-94f6-e01cd2c07765</td></tr><tr><td>653084</td><td>400.0</td><td>400.0</td><td>Milk Sales</td><td>Food</td><td>to purchase one buffalo.</td><td>PK</td><td>Pakistan</td><td>Abdul Hakeem</td><td>PKR</td><td>245.0</td><td>2014-01-01T11:53:19Z</td><td>2013-12-17 08:00:00+00:00</td><td>2014-01-01 19:18:51+00:00</td><td>14.0</td><td>16</td><td>null</td><td>female</td><td>monthly</td><td>2014-01-01</td><td>2014</td><td>1</td><td>2025-05-22T08:10:04.626Z</td><td>adb0de9d-7c7e-4448-94f6-e01cd2c07765</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "653051",
         "300.0",
         "300.0",
         "Fruits & Vegetables",
         "Food",
         "To buy seasonal, fresh fruits to sell. ",
         "PK",
         "Pakistan",
         "Lahore",
         "PKR",
         "247.0",
         "2014-01-01T06:12:39Z",
         "2013-12-17 08:00:00+00:00",
         "2014-01-02 10:06:32+00:00",
         "12.0",
         "12",
         null,
         "female",
         "irregular",
         "2014-01-01",
         2014,
         1,
         "2025-05-22T08:10:04.626Z",
         "adb0de9d-7c7e-4448-94f6-e01cd2c07765"
        ],
        [
         "653053",
         "575.0",
         "575.0",
         "Rickshaw",
         "Transportation",
         "to repair and maintain the auto rickshaw used in their business.",
         "PK",
         "Pakistan",
         "Lahore",
         "PKR",
         "247.0",
         "2014-01-01T06:51:08Z",
         "2013-12-17 08:00:00+00:00",
         "2014-01-02 09:17:23+00:00",
         "11.0",
         "14",
         null,
         "female, female",
         "irregular",
         "2014-01-01",
         2014,
         1,
         "2025-05-22T08:10:04.626Z",
         "adb0de9d-7c7e-4448-94f6-e01cd2c07765"
        ],
        [
         "653068",
         "150.0",
         "150.0",
         "Transportation",
         "Transportation",
         "To repair their old cycle-van and buy another one to rent out as a source of income",
         "IN",
         "India",
         "Maynaguri",
         "INR",
         "334.0",
         "2014-01-01T09:58:07Z",
         "2013-12-17 08:00:00+00:00",
         "2014-01-01 16:01:36+00:00",
         "43.0",
         "6",
         "user_favorite, user_favorite",
         "female",
         "bullet",
         "2014-01-01",
         2014,
         1,
         "2025-05-22T08:10:04.626Z",
         "adb0de9d-7c7e-4448-94f6-e01cd2c07765"
        ],
        [
         "653063",
         "200.0",
         "200.0",
         "Embroidery",
         "Arts",
         "to purchase an embroidery machine and a variety of new embroidery materials.",
         "PK",
         "Pakistan",
         "Lahore",
         "PKR",
         "247.0",
         "2014-01-01T08:03:11Z",
         "2013-12-24 08:00:00+00:00",
         "2014-01-01 13:00:00+00:00",
         "11.0",
         "8",
         null,
         "female",
         "irregular",
         "2014-01-01",
         2014,
         1,
         "2025-05-22T08:10:04.626Z",
         "adb0de9d-7c7e-4448-94f6-e01cd2c07765"
        ],
        [
         "653084",
         "400.0",
         "400.0",
         "Milk Sales",
         "Food",
         "to purchase one buffalo.",
         "PK",
         "Pakistan",
         "Abdul Hakeem",
         "PKR",
         "245.0",
         "2014-01-01T11:53:19Z",
         "2013-12-17 08:00:00+00:00",
         "2014-01-01 19:18:51+00:00",
         "14.0",
         "16",
         null,
         "female",
         "monthly",
         "2014-01-01",
         2014,
         1,
         "2025-05-22T08:10:04.626Z",
         "adb0de9d-7c7e-4448-94f6-e01cd2c07765"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "funded_amount",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "loan_amount",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "activity",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sector",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "use",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country_code",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "region",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "currency",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "partner_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "posted_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "disbursed_time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "funded_time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "term_in_months",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lender_count",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tags",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "borrower_genders",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "repayment_interval",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "posted_year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "posted_month",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "ingestion_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "batch_id",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posted time range: 2014-01-01 04:49:26 - 2017-07-26 06:31:46\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file\n",
    "print(f\"Reading CSV file: {csv_path}\")\n",
    "\n",
    "try:\n",
    "    df_csv = spark.read.format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(csv_path)\n",
    "    \n",
    "    # Check if posted_time column exists\n",
    "    if \"posted_time\" not in df_csv.columns:\n",
    "        raise Exception(\"Column 'posted_time' not found in CSV file!\")\n",
    "    \n",
    "    # Convert posted_time to date/timestamp format (if it's string)\n",
    "    df_csv = df_csv.withColumn(\"posted_time\", \n",
    "                               when(col(\"posted_time\").isNotNull(), \n",
    "                                   to_timestamp(col(\"posted_time\")))\n",
    "                               .otherwise(None))\n",
    "    \n",
    "    # Extract year and month information from posted_time for partitioning\n",
    "    df_csv = df_csv.withColumn(\"posted_year\", year(col(\"posted_time\"))) \\\n",
    "                   .withColumn(\"posted_month\", month(col(\"posted_time\")))\n",
    "    \n",
    "    # Add processing metadata\n",
    "    df_new_data = df_csv \\\n",
    "        .withColumn(\"ingestion_date\", current_timestamp()) \\\n",
    "        .withColumn(\"batch_id\", lit(str(uuid.uuid4())))\n",
    "    \n",
    "    print(f\"CSV file read. New data row count: {df_new_data.count()}\")\n",
    "    print(\"Schema information:\")\n",
    "    df_new_data.printSchema()\n",
    "    \n",
    "    print(\"Sample data:\")\n",
    "    display(df_new_data.limit(5))\n",
    "    \n",
    "    # Show posted_time date range\n",
    "    date_range = df_new_data.select(min(\"posted_time\").alias(\"min_date\"), \n",
    "                                   max(\"posted_time\").alias(\"max_date\")).collect()[0]\n",
    "    print(f\"Posted time range: {date_range['min_date']} - {date_range['max_date']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"CSV reading error: {str(e)}\")\n",
    "    dbutils.notebook.exit(f\"CSV reading error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "449e5205-de77-494d-afe0-28fa7b5fed0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check existence of key column for incremental loading\n",
    "if incremental_key and incremental_key not in df_new_data.columns:\n",
    "    error_msg = f\"Key column '{incremental_key}' specified for incremental loading not found in CSV file!\"\n",
    "    print(error_msg)\n",
    "    dbutils.notebook.exit(error_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d666c7cd-484d-4fb2-b76f-cb89188cc4c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing partition 2014/04 ===\n",
      "New data count for this partition: 13467\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/04\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 13467\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/04\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/04\n",
      "Total rows written: 13467\n",
      "\n",
      "=== Processing partition 2014/10 ===\n",
      "New data count for this partition: 16348\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/10\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16348\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/10\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/10\n",
      "Total rows written: 16348\n",
      "\n",
      "=== Processing partition 2014/12 ===\n",
      "New data count for this partition: 14997\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/12\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14997\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/12\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/12\n",
      "Total rows written: 14997\n",
      "\n",
      "=== Processing partition 2014/05 ===\n",
      "New data count for this partition: 14068\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/05\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14068\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/05\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/05\n",
      "Total rows written: 14068\n",
      "\n",
      "=== Processing partition 2014/01 ===\n",
      "New data count for this partition: 11708\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/01\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 11708\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/01\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/01\n",
      "Total rows written: 11708\n",
      "\n",
      "=== Processing partition 2014/08 ===\n",
      "New data count for this partition: 14670\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/08\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14670\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/08\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/08\n",
      "Total rows written: 14670\n",
      "\n",
      "=== Processing partition 2014/09 ===\n",
      "New data count for this partition: 15380\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/09\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 15380\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/09\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/09\n",
      "Total rows written: 15380\n",
      "\n",
      "=== Processing partition 2014/03 ===\n",
      "New data count for this partition: 13588\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/03\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 13588\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/03\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/03\n",
      "Total rows written: 13588\n",
      "\n",
      "=== Processing partition 2014/02 ===\n",
      "New data count for this partition: 13658\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/02\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 13658\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/02\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/02\n",
      "Total rows written: 13658\n",
      "\n",
      "=== Processing partition 2014/06 ===\n",
      "New data count for this partition: 14260\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/06\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14260\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/06\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/06\n",
      "Total rows written: 14260\n",
      "\n",
      "=== Processing partition 2015/07 ===\n",
      "New data count for this partition: 15905\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/07\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 15905\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/07\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/07\n",
      "Total rows written: 15905\n",
      "\n",
      "=== Processing partition 2014/11 ===\n",
      "New data count for this partition: 16437\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/11\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16437\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/11\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/11\n",
      "Total rows written: 16437\n",
      "\n",
      "=== Processing partition 2015/01 ===\n",
      "New data count for this partition: 12368\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/01\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 12368\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/01\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/01\n",
      "Total rows written: 12368\n",
      "\n",
      "=== Processing partition 2014/07 ===\n",
      "New data count for this partition: 15185\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/07\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 15185\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/07\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2014/07\n",
      "Total rows written: 15185\n",
      "\n",
      "=== Processing partition 2015/02 ===\n",
      "New data count for this partition: 14042\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/02\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14042\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/02\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/02\n",
      "Total rows written: 14042\n",
      "\n",
      "=== Processing partition 2015/12 ===\n",
      "New data count for this partition: 14847\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/12\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14847\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/12\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/12\n",
      "Total rows written: 14847\n",
      "\n",
      "=== Processing partition 2015/04 ===\n",
      "New data count for this partition: 14260\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/04\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14260\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/04\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/04\n",
      "Total rows written: 14260\n",
      "\n",
      "=== Processing partition 2015/08 ===\n",
      "New data count for this partition: 14714\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/08\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14714\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/08\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/08\n",
      "Total rows written: 14714\n",
      "\n",
      "=== Processing partition 2015/11 ===\n",
      "New data count for this partition: 15827\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/11\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 15827\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/11\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/11\n",
      "Total rows written: 15827\n",
      "\n",
      "=== Processing partition 2015/09 ===\n",
      "New data count for this partition: 14893\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/09\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14893\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/09\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/09\n",
      "Total rows written: 14893\n",
      "\n",
      "=== Processing partition 2015/10 ===\n",
      "New data count for this partition: 16051\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/10\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16051\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/10\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/10\n",
      "Total rows written: 16051\n",
      "\n",
      "=== Processing partition 2015/03 ===\n",
      "New data count for this partition: 16206\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/03\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16206\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/03\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/03\n",
      "Total rows written: 16206\n",
      "\n",
      "=== Processing partition 2015/06 ===\n",
      "New data count for this partition: 16293\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/06\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16293\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/06\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/06\n",
      "Total rows written: 16293\n",
      "\n",
      "=== Processing partition 2015/05 ===\n",
      "New data count for this partition: 16039\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/05\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16039\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/05\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2015/05\n",
      "Total rows written: 16039\n",
      "\n",
      "=== Processing partition 2016/07 ===\n",
      "New data count for this partition: 16748\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/07\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16748\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/07\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/07\n",
      "Total rows written: 16748\n",
      "\n",
      "=== Processing partition 2016/11 ===\n",
      "New data count for this partition: 18467\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/11\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 18467\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/11\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/11\n",
      "Total rows written: 18467\n",
      "\n",
      "=== Processing partition 2016/05 ===\n",
      "New data count for this partition: 16196\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/05\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16196\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/05\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/05\n",
      "Total rows written: 16196\n",
      "\n",
      "=== Processing partition 2016/02 ===\n",
      "New data count for this partition: 14785\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/02\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 14785\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/02\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/02\n",
      "Total rows written: 14785\n",
      "\n",
      "=== Processing partition 2016/09 ===\n",
      "New data count for this partition: 17925\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/09\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 17925\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/09\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/09\n",
      "Total rows written: 17925\n",
      "\n",
      "=== Processing partition 2016/10 ===\n",
      "New data count for this partition: 16633\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/10\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16633\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/10\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/10\n",
      "Total rows written: 16633\n",
      "\n",
      "=== Processing partition 2016/06 ===\n",
      "New data count for this partition: 17204\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/06\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 17204\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/06\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/06\n",
      "Total rows written: 17204\n",
      "\n",
      "=== Processing partition 2016/01 ===\n",
      "New data count for this partition: 13538\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/01\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 13538\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/01\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/01\n",
      "Total rows written: 13538\n",
      "\n",
      "=== Processing partition 2016/04 ===\n",
      "New data count for this partition: 15362\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/04\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 15362\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/04\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/04\n",
      "Total rows written: 15362\n",
      "\n",
      "=== Processing partition 2016/08 ===\n",
      "New data count for this partition: 16422\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/08\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16422\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/08\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/08\n",
      "Total rows written: 16422\n",
      "\n",
      "=== Processing partition 2016/03 ===\n",
      "New data count for this partition: 16803\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/03\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16803\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/03\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/03\n",
      "Total rows written: 16803\n",
      "\n",
      "=== Processing partition 2017/03 ===\n",
      "New data count for this partition: 22942\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/03\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 22942\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/03\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/03\n",
      "Total rows written: 22942\n",
      "\n",
      "=== Processing partition 2017/07 ===\n",
      "New data count for this partition: 3704\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/07\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 3704\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/07\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/07\n",
      "Total rows written: 3704\n",
      "\n",
      "=== Processing partition 2016/12 ===\n",
      "New data count for this partition: 16992\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/12\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16992\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/12\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2016/12\n",
      "Total rows written: 16992\n",
      "\n",
      "=== Processing partition 2017/04 ===\n",
      "New data count for this partition: 17756\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/04\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 17756\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/04\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/04\n",
      "Total rows written: 17756\n",
      "\n",
      "=== Processing partition 2017/02 ===\n",
      "New data count for this partition: 17689\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/02\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 17689\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/02\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/02\n",
      "Total rows written: 17689\n",
      "\n",
      "=== Processing partition 2017/05 ===\n",
      "New data count for this partition: 21252\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/05\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 21252\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/05\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/05\n",
      "Total rows written: 21252\n",
      "\n",
      "=== Processing partition 2017/06 ===\n",
      "New data count for this partition: 18396\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/06\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 18396\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/06\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/06\n",
      "Total rows written: 18396\n",
      "\n",
      "=== Processing partition 2017/01 ===\n",
      "New data count for this partition: 16108\n",
      "Bronze data not found: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/01\n",
      "No existing Bronze data found. New data will be written.\n",
      "Removing duplicates based on id...\n",
      "Data row count after deduplication: 16108\n",
      "Writing data to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/01\n",
      "Data successfully written to Bronze layer: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net/2017/01\n",
      "Total rows written: 16108\n"
     ]
    }
   ],
   "source": [
    "# Process year/month based - separate partition for each year/month\n",
    "years_months = df_new_data.select(\"posted_year\", \"posted_month\").distinct().collect()\n",
    "\n",
    "for row in years_months:\n",
    "    year = row[\"posted_year\"]\n",
    "    month = row[\"posted_month\"]\n",
    "    \n",
    "    if year is None or month is None:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n=== Processing partition {year}/{month:02d} ===\")\n",
    "    \n",
    "    # Bronze layer path for this year/month\n",
    "    bronze_output_path = f\"{bronze_base_path}/{year}/{month:02d}\"\n",
    "    \n",
    "    # Filter data for this partition\n",
    "    df_partition_new = df_new_data.filter((col(\"posted_year\") == year) & \n",
    "                                         (col(\"posted_month\") == month))\n",
    "    partition_new_count = df_partition_new.count()\n",
    "    print(f\"New data count for this partition: {partition_new_count}\")\n",
    "    \n",
    "    # Check and read existing Bronze data\n",
    "    bronze_exists = False\n",
    "    try:\n",
    "        # Check if bronze folder exists\n",
    "        dbutils.fs.ls(bronze_output_path)\n",
    "        bronze_exists = True\n",
    "        print(f\"Existing Bronze data found: {bronze_output_path}\")\n",
    "        \n",
    "        # Read existing Bronze data\n",
    "        df_existing_bronze = spark.read.format(\"parquet\").load(bronze_output_path)\n",
    "        existing_count = df_existing_bronze.count()\n",
    "        print(f\"Existing Bronze data row count: {existing_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Bronze data not found: {bronze_output_path}\")\n",
    "        bronze_exists = False\n",
    "    \n",
    "    # Incremental loading strategy\n",
    "    if bronze_exists and not overwrite_partition:\n",
    "        print(f\"Performing incremental loading, key column: {incremental_key}\")\n",
    "        \n",
    "        # Find the latest value in existing data\n",
    "        if incremental_key in df_existing_bronze.columns:\n",
    "            max_existing_value = df_existing_bronze.agg({incremental_key: \"max\"}).collect()[0][0]\n",
    "            print(f\"Latest {incremental_key} value in existing data: {max_existing_value}\")\n",
    "            \n",
    "            # Filter new data - only take records not in existing dataset\n",
    "            df_to_append = df_partition_new.filter(col(incremental_key) > max_existing_value)\n",
    "            append_count = df_to_append.count()\n",
    "            print(f\"New records to append: {append_count}\")\n",
    "            \n",
    "            if append_count > 0:\n",
    "                # Union operation\n",
    "                df_final = df_existing_bronze.union(df_to_append)\n",
    "            else:\n",
    "                print(\"No new data to append, keeping existing data.\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"{incremental_key} column not found in existing Bronze data. Adding all new data.\")\n",
    "            df_final = df_existing_bronze.union(df_partition_new)\n",
    "    else:\n",
    "        # Use only new data if no existing data or overwrite is selected\n",
    "        if not bronze_exists:\n",
    "            print(\"No existing Bronze data found. New data will be written.\")\n",
    "        elif overwrite_partition:\n",
    "            print(\"Overwrite existing partition selected. New data will be written.\")\n",
    "        \n",
    "        df_final = df_partition_new\n",
    "    \n",
    "    # Remove duplicates (based on incremental_key)\n",
    "    print(f\"Removing duplicates based on {incremental_key}...\")\n",
    "    \n",
    "    # Use window function to select latest version for each record\n",
    "    window = Window.partitionBy(incremental_key).orderBy(desc(\"ingestion_date\"))\n",
    "    df_deduplicated = df_final.withColumn(\"row_num\", row_number().over(window)) \\\n",
    "                             .filter(col(\"row_num\") == 1) \\\n",
    "                             .drop(\"row_num\")\n",
    "    \n",
    "    final_count = df_deduplicated.count()\n",
    "    print(f\"Data row count after deduplication: {final_count}\")\n",
    "    \n",
    "    # Write to Bronze layer as Parquet\n",
    "    print(f\"Writing data to Bronze layer: {bronze_output_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Write in Parquet format\n",
    "        df_deduplicated.write \\\n",
    "            .format(\"parquet\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save(bronze_output_path)\n",
    "        \n",
    "        print(f\"Data successfully written to Bronze layer: {bronze_output_path}\")\n",
    "        print(f\"Total rows written: {final_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to Bronze layer: {str(e)}\")\n",
    "        dbutils.notebook.exit(f\"Error writing to Bronze layer: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b294db-5693-474d-b5c9-f66d588e2f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Summary ===\n",
      "Process completed successfully!\n",
      "Total processed row count: 672113\n",
      "Bronze base path: abfss://kivabronze@kivastorageacc2.dfs.core.windows.net\n",
      "Processed year/month partitions:\n"
     ]
    }
   ],
   "source": [
    "# Report processing results\n",
    "total_processed = df_new_data.count()\n",
    "print(\"\\n=== Processing Summary ===\")\n",
    "print(\"Process completed successfully!\")\n",
    "print(f\"Total processed row count: {total_processed}\")\n",
    "print(f\"Bronze base path: {bronze_base_path}\")\n",
    "print(f\"Processed year/month partitions:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dc8e2ce-9360-4e99-873d-479f4202b503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 2014/04\n",
      "  - 2014/10\n",
      "  - 2014/12\n",
      "  - 2014/05\n",
      "  - 2014/01\n",
      "  - 2014/08\n",
      "  - 2014/09\n",
      "  - 2014/03\n",
      "  - 2014/02\n",
      "  - 2014/06\n",
      "  - 2015/07\n",
      "  - 2014/11\n",
      "  - 2015/01\n",
      "  - 2014/07\n",
      "  - 2015/02\n",
      "  - 2015/12\n",
      "  - 2015/04\n",
      "  - 2015/08\n",
      "  - 2015/11\n",
      "  - 2015/09\n",
      "  - 2015/10\n",
      "  - 2015/03\n",
      "  - 2015/06\n",
      "  - 2015/05\n",
      "  - 2016/07\n",
      "  - 2016/11\n",
      "  - 2016/05\n",
      "  - 2016/02\n",
      "  - 2016/09\n",
      "  - 2016/10\n",
      "  - 2016/06\n",
      "  - 2016/01\n",
      "  - 2016/04\n",
      "  - 2016/08\n",
      "  - 2016/03\n",
      "  - 2017/03\n",
      "  - 2017/07\n",
      "  - 2016/12\n",
      "  - 2017/04\n",
      "  - 2017/02\n",
      "  - 2017/05\n",
      "  - 2017/06\n",
      "  - 2017/01\n"
     ]
    }
   ],
   "source": [
    "for row in years_months:\n",
    "    year = row[\"posted_year\"] \n",
    "    month = row[\"posted_month\"]\n",
    "    if year is not None and month is not None:\n",
    "        print(f\"  - {year}/{month:02d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85cdcf21-0205-4198-9157-5a5974cc5b2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Return output of this notebook as dict (can be used in ADF)\n",
    "output = {\n",
    "    \"status\": \"success\",\n",
    "    \"processed_rows\": total_processed,\n",
    "    \"bronze_base_path\": bronze_base_path,\n",
    "    \"partitions_processed\": len([r for r in years_months if r[\"posted_year\"] is not None]),\n",
    "    \"process_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"incremental_key\": incremental_key\n",
    "}\n",
    "\n",
    "dbutils.notebook.exit(str(output))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "csv_to_Bronze Notebook 2025-05-21 16:02:13",
   "widgets": {
    "bronze_container": {
     "currentValue": "kivabronze",
     "nuid": "56414f05-3726-439f-ab0f-325cd74b5b32",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "kivabronze",
      "label": "Bronze Container Name",
      "name": "bronze_container",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "kivabronze",
      "label": "Bronze Container Name",
      "name": "bronze_container",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "csv_path": {
     "currentValue": "abfss://code@kivastorageacc2.dfs.core.windows.net/kiva_loans.csv",
     "nuid": "83444081-3b78-41b8-a920-f1be022a33c0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "abfss://code@kivastorageacc2.dfs.core.windows.net/kiva_loans.csv",
      "label": "CSV File Path (ADLS)",
      "name": "csv_path",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "abfss://code@kivastorageacc2.dfs.core.windows.net/kiva_loans.csv",
      "label": "CSV File Path (ADLS)",
      "name": "csv_path",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "incremental_key": {
     "currentValue": "id",
     "nuid": "3b930dde-cccc-4b78-ac57-2297eda8ab13",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "id",
      "label": "Incremental Loading Key Column",
      "name": "incremental_key",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "id",
      "label": "Incremental Loading Key Column",
      "name": "incremental_key",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "overwrite_partition": {
     "currentValue": "false",
     "nuid": "6e2bf782-492b-4ba6-8164-271ddf89a8c5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "false",
      "label": "Overwrite Existing Partition",
      "name": "overwrite_partition",
      "options": {
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false,
       "widgetDisplayType": "Dropdown"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "false",
      "label": "Overwrite Existing Partition",
      "name": "overwrite_partition",
      "options": {
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ],
       "widgetType": "dropdown"
      },
      "widgetType": "dropdown"
     }
    },
    "storage_account_name": {
     "currentValue": "kivastorageacc2",
     "nuid": "526cacec-adab-4447-9dda-9f0f46939d5c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "kivastorageacc2",
      "label": "Storage Account Name",
      "name": "storage_account_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "kivastorageacc2",
      "label": "Storage Account Name",
      "name": "storage_account_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
